{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import sys\n",
    "import urllib.parse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rdflib\n",
    "import requests\n",
    "from SPARQLWrapper import SPARQLWrapper, XML\n",
    "from SPARQLWrapper.SPARQLExceptions import EndPointInternalError\n",
    "from rdflib import Graph\n",
    "from rdflib.plugin import register, Parser\n",
    "\n",
    "from utils import load_metadata_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DUMP_DATE = '2021-08-14'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lod_data = load_metadata_json(DUMP_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[4mTabular View\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1mMedia Type                                     Frequency\u001B[0m\n",
      "meta/owl                                           27        \n",
      "n-quads                                            32        \n",
      "text/plain                                         48        \n",
      "meta/sitemap                                       55        \n",
      "text/xml                                           70        \n",
      "application/x-ntriples                             79        \n",
      "None                                               82        \n",
      "application/x-gzip                                 86        \n",
      "application/x-nquads                               102       \n",
      "HTML                                               112       \n",
      "Others                                             114       \n",
      "application/rdf+xml                                132       \n",
      "application/octet-stream                           160       \n",
      "application/zip                                    162       \n",
      "meta/void                                          242       \n",
      "text/turtle                                        253       \n",
      "RDF                                                306       \n",
      "meta/rdf-schema                                    345       \n",
      "text/html                                          1272      \n",
      "Total text/html in RDFa: 0\n"
     ]
    }
   ],
   "source": [
    "### Identify the different Media Types used within the LOD Cloud dataset metadata\n",
    "\n",
    "register('rdfa', Parser, 'rdflib.plugins.parsers.rdfa', 'RDFaParser')\n",
    "\n",
    "rdfaCounter = 0\n",
    "counter = 0\n",
    "\n",
    "\n",
    "# Different Media Types Used\n",
    "def __extractMediaType(item):\n",
    "    global rdfaCounter\n",
    "    global counter\n",
    "    mtype = item[\"media_type\"]\n",
    "    if (\";\" in mtype):\n",
    "        mtype = mtype[:mtype.find(';')]\n",
    "    mtype = str(mtype)\n",
    "    if mtype == \"text/html\":\n",
    "        if \"access_url\" in item:\n",
    "            try:\n",
    "                h = requests.get(str(item[\"access_url\"]).strip(), timeout=10)\n",
    "                if h.status_code > 399:\n",
    "                    g = Graph()\n",
    "                    g.parse(str(item[\"access_url\"]).strip(), 'rdfa')\n",
    "                    if (len(g) > 1):\n",
    "                        rdfaCounter = rdfaCounter + 1\n",
    "            except:\n",
    "                pass\n",
    "    if (len(mtype) == 0):\n",
    "        mtype = \"None\"\n",
    "    if (mtype in mediaTypes):\n",
    "        mediaTypes[mtype] = mediaTypes[mtype] + 1\n",
    "    else:\n",
    "        mediaTypes[mtype] = 1\n",
    "\n",
    "\n",
    "mediaTypes = dict({})\n",
    "# Get Different Media Types\n",
    "for key in lod_data:\n",
    "    full_download = lod_data[key][\"full_download\"]\n",
    "    other_download = lod_data[key][\"other_download\"]\n",
    "\n",
    "    if (len(full_download) > 0):\n",
    "        for item in full_download:\n",
    "            if (\"media_type\" in item):\n",
    "                __extractMediaType(item)\n",
    "    if (len(other_download) > 0):\n",
    "        for item in other_download:\n",
    "            if (\"media_type\" in item):\n",
    "                __extractMediaType(item)\n",
    "\n",
    "# Create Chart\n",
    "toPlot = {\"Others\": 0}\n",
    "\n",
    "for (k, v) in mediaTypes.items():\n",
    "    if k == \"text/html\":\n",
    "        #         skip text/html as it would be large to print\n",
    "        continue\n",
    "    if v > 25:\n",
    "        toPlot[k] = v\n",
    "    else:\n",
    "        toPlot[\"Others\"] = toPlot[\"Others\"] + 1\n",
    "\n",
    "# Display Table\n",
    "print(\"\\033[4mTabular View\\033[0m\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "toPlot[\"text/html\"] = mediaTypes[\"text/html\"]\n",
    "sorted_toPlot = sorted(toPlot.items(), key=lambda kv: kv[1])\n",
    "print(\"{:<50} {:<10}\".format('\\033[1m' + 'Media Type', 'Frequency' + '\\033[0m'))\n",
    "for k, v in sorted_toPlot:\n",
    "    print(\"{:<50} {:<10}\".format(k, v))\n",
    "\n",
    "print(\"Total text/html in RDFa: \" + str(rdfaCounter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Identify the Dataset's Accessibility based on the LOD Cloud available metadata\n",
    "\n",
    "acceptable_media_types = set()\n",
    "acceptable_media_types.add(\"application/x-ntriples\")\n",
    "acceptable_media_types.add(\"application/rdf+xml\")\n",
    "acceptable_media_types.add(\"text/turtle\")\n",
    "acceptable_media_types.add(\"application/x-nquads\")\n",
    "acceptable_media_types.add(\"application/trig\")\n",
    "acceptable_media_types.add(\"application/n-triples\")\n",
    "acceptable_media_types.add(\"gzip:ntriples\")\n",
    "acceptable_media_types.add(\"application/x-gzip\")\n",
    "acceptable_media_types.add(\"application/octet-stream\")\n",
    "acceptable_media_types.add(\"application/x-ntriples\")\n",
    "acceptable_media_types.add(\"RDF\")\n",
    "acceptable_media_types.add(\"plain/text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def __query_endpoint(uri):\n",
    "    try:\n",
    "        sparql_query = SPARQLWrapper(uri)\n",
    "        sparql_query.setQuery('ASK {?s ?p ?o}')\n",
    "        sparql_query.setReturnFormat(XML)\n",
    "        sparql_query.setTimeout(3)\n",
    "        results = sparql_query.query().convert()\n",
    "        for _ in results.getElementsByTagName('boolean'):\n",
    "            return True\n",
    "        return False\n",
    "    except (EndPointInternalError, AttributeError):\n",
    "        try:\n",
    "            params = urllib.parse.urlencode({'query': 'ASK {?s ?p ?o}'})\n",
    "            results = requests.get(f'{uri}?{params}', headers={'Accept': 'application/sparql-results+json'},\n",
    "                                   timeout=3).json()\n",
    "            if results['boolean'] is not None:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        except:\n",
    "            try:\n",
    "                params = urllib.parse.urlencode({'query': 'ASK {?s ?p ?o}'})\n",
    "                data = requests.get(f'{uri}?{params}', timeout=3).text\n",
    "                if data:\n",
    "                    return True\n",
    "                else:\n",
    "                    return False\n",
    "            except:\n",
    "                e = sys.exc_info()[0]\n",
    "                return False\n",
    "    except:\n",
    "        e = sys.exc_info()[0]\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def __query_void(voidurl):\n",
    "    if __checkstatus(voidurl):\n",
    "        try:\n",
    "            graph = rdflib.Graph()\n",
    "            graph.parse(voidurl)\n",
    "            accessible = False\n",
    "\n",
    "            result = graph.query('ASK { ?s a <http://rdfs.org/ns/void#Dataset> . }')\n",
    "            for row in result:\n",
    "                accessible = bool(row)\n",
    "\n",
    "            return accessible\n",
    "        except:\n",
    "            e = sys.exc_info()[0]\n",
    "            return False\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def __checkstatus(host):\n",
    "    try:\n",
    "        h = requests.get(host, timeout=10)\n",
    "        if h.status_code > 399:\n",
    "            return False\n",
    "    except:\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def availableSPARQLEntryPoint(record):\n",
    "    if \"sparql\" in record:\n",
    "        if len(record[\"sparql\"]) >= 1:\n",
    "            sparqlEndpoint = record[\"sparql\"][0][\"access_url\"]\n",
    "\n",
    "            if not (\"FAIL\" in record[\"sparql\"][0][\"status\"]):\n",
    "                if __checkstatus(sparqlEndpoint):\n",
    "                    return __query_endpoint(sparqlEndpoint)\n",
    "                else:\n",
    "                    return False\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def availableDatadumpEntryPoint(record):\n",
    "    datadumpLocation = []\n",
    "    _full_download = record[\"full_download\"]\n",
    "    _other_download = record[\"other_download\"]\n",
    "    if (len(_full_download) > 0):\n",
    "        for item in _full_download:\n",
    "            if (\"media_type\" in item):\n",
    "                mtype = item[\"media_type\"]\n",
    "                if (\";\" in mtype):\n",
    "                    mtype = mtype[:mtype.find(';')]\n",
    "                if (item[\"media_type\"] in acceptable_media_types):\n",
    "                    if (not (\".well-known/\" in item[\"download_url\"])):\n",
    "                        if (__checkstatus(item[\"download_url\"])):\n",
    "                            datadumpLocation.append(item[\"download_url\"])\n",
    "    elif (len(_other_download) > 0):\n",
    "        for item in _other_download:\n",
    "            if (not (\".well-known/\" in item[\"access_url\"])):\n",
    "                if (item[\"media_type\"] in acceptable_media_types):\n",
    "                    if (__checkstatus(item[\"access_url\"])):\n",
    "                        datadumpLocation.append(item[\"access_url\"])\n",
    "\n",
    "    return len(datadumpLocation) > 0\n",
    "\n",
    "\n",
    "def availableVoidEntryPoint(record):\n",
    "    voidLocation = []\n",
    "    full_download = record[\"full_download\"]\n",
    "    other_download = record[\"other_download\"]\n",
    "    if (len(full_download) > 0):\n",
    "        for item in full_download:\n",
    "            if (\"media_type\" in item):\n",
    "                mtype = item[\"media_type\"]\n",
    "                if (\";\" in mtype):\n",
    "                    mtype = mtype[:mtype.find(';')]\n",
    "                if (item[\"media_type\"] == \"meta/void\"):\n",
    "                    if (__checkstatus(item[\"download_url\"])):\n",
    "                        voidLocation.append(item[\"download_url\"])\n",
    "                elif (\".well-known/\" in item[\"download_url\"]):\n",
    "                    if (__checkstatus(item[\"download_url\"])):\n",
    "                        voidLocation.append(item[\"download_url\"])\n",
    "\n",
    "    elif (len(other_download) > 0):\n",
    "        for item in other_download:\n",
    "            if (item[\"media_type\"] == \"meta/void\"):\n",
    "                if (__checkstatus(item[\"access_url\"])):\n",
    "                    voidLocation.append(item[\"access_url\"])\n",
    "            elif (\".well-known/\" in item[\"access_url\"]):\n",
    "                voidLocation.append(item[\"access_url\"])\n",
    "\n",
    "    return len(voidLocation) > 0\n",
    "\n",
    "\n",
    "dataSources = dict({})  # key, (dd,sparql,void) 1 = available 0 = not available\n",
    "for key in lod_data:\n",
    "    dataSources[key] = (availableDatadumpEntryPoint(lod_data[key]), availableSPARQLEntryPoint(lod_data[key]),\n",
    "                        availableVoidEntryPoint(lod_data[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The next snippet checks the number of datasets that have no access point\n",
    "noAccessPoint = 0\n",
    "\n",
    "for key in lod_data:\n",
    "    full_download = lod_data[key][\"full_download\"]\n",
    "    other_download = lod_data[key][\"other_download\"]\n",
    "    sparql = lod_data[key][\"sparql\"]\n",
    "\n",
    "    if ((len(full_download) == 0) and (len(other_download) == 0) and (len(sparql) == 0)):\n",
    "        noAccessPoint = noAccessPoint + 1\n",
    "\n",
    "print(\"Number of datasets without an access point: \" + str(noAccessPoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This snippet will create a JSON file that can be used to recreate the LOD cloud visualisation.The LOD cloud diagram\n",
    "# code can be found here: https: // github.com / lod - cloud / lod - cloud - draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "available_lod_data = load_metadata_json(DUMP_DATE)\n",
    "\n",
    "modified_dataSources = dict(dataSources)\n",
    "for (k, v) in dataSources.items():\n",
    "    if v == (0, 0, 0):\n",
    "        del modified_dataSources[k]\n",
    "        del available_lod_data[k]\n",
    "\n",
    "print(json.dumps(available_lod_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following code snippet will identify the different access points of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dd = 0\n",
    "sparql = 0\n",
    "void = 0\n",
    "ddSparql = 0\n",
    "ddVoid = 0\n",
    "SparqlVoid = 0\n",
    "allthree = 0\n",
    "nothing = 0\n",
    "for (k, v) in dataSources.items():\n",
    "    if v == (0, 0, 0):\n",
    "        nothing += 1\n",
    "    if v == (1, 0, 0):\n",
    "        dd += 1\n",
    "    if v == (0, 1, 0):\n",
    "        sparql += 1\n",
    "    if v == (0, 0, 1):\n",
    "        void += 1\n",
    "    if v == (1, 1, 0):\n",
    "        ddSparql += 1\n",
    "    if v == (1, 0, 1):\n",
    "        ddVoid += 1\n",
    "    if v == (0, 1, 1):\n",
    "        SparqlVoid += 1\n",
    "    if v == (1, 1, 1):\n",
    "        allthree += 1\n",
    "\n",
    "print(\"Only Datadump: \" + str(dd))\n",
    "print(\"Only SPARQL: \" + str(sparql))\n",
    "print(\"Only VOID: \" + str(void))\n",
    "print(\"Only Datadump and SPARQL: \" + str(ddSparql))\n",
    "print(\"Only Datadump and VOID: \" + str(ddVoid))\n",
    "print(\"Only SPARQL and VOID: \" + str(SparqlVoid))\n",
    "print(\"All three entry points: \" + str(allthree))\n",
    "print(\"No entry points: \" + str(nothing))\n",
    "\n",
    "labels = 'Datadump', 'SPARQL', 'voID', 'More than 1\\nDiscoverability\\nEntry', 'None'\n",
    "sizes = [dd, sparql, void, (ddSparql + ddVoid + SparqlVoid + allthree), nothing]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "patches, texts, autotexts = ax.pie(sizes, labels=labels, autopct='%1.1f%%', shadow=False, startangle=90,\n",
    "                                   textprops={'fontsize': 12})\n",
    "texts[0].set_fontsize(15)\n",
    "texts[1].set_fontsize(15)\n",
    "texts[2].set_fontsize(15)\n",
    "texts[3].set_fontsize(15)\n",
    "texts[4].set_fontsize(15)\n",
    "\n",
    "ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Identifying Licenses\n",
    "\n",
    "# Licences are the heart of Open Data.They define whether third parties can re - use data or otherwise, and to what\n",
    "# extent.For this experiment we parsed through each dataset in the data file and looked for the value attributed to the\n",
    "# `license` key.\n",
    "\n",
    "# The next code snippet parses through the LOD Cloud data and checks the license for each dataset.The variable\n",
    "# `licensesUsed` stores all licenses used and their frequency.\n",
    "licensesUsed = dict({})\n",
    "for key in lod_data:\n",
    "    if (\"license\" in lod_data[key]):\n",
    "        theLicence = lod_data[key][\"license\"]\n",
    "        if theLicence == \"\":\n",
    "            continue\n",
    "        if not (theLicence in licensesUsed):\n",
    "            licensesUsed[theLicence] = 1\n",
    "        else:\n",
    "            licensesUsed[theLicence] = licensesUsed[theLicence] + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising the licenses used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Class used to visualse the data\n",
    "def visualiseLicenseData(licenses_used):\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    ax.barh(licenses_used.keys(), licenses_used.values(), height=0.5)\n",
    "    ax.set_yticks(np.arange(len(licenses_used.keys())))\n",
    "    ax.set_yticklabels(licenses_used.keys(), fontsize=12, fontweight='bold')\n",
    "    ax.invert_yaxis()\n",
    "    plt.xlabel(\"Frequency\", fontsize=15, fontweight='bold')\n",
    "\n",
    "    for i, v in enumerate(licenses_used.values()):\n",
    "        ax.text(v + 2, i + 0.08, str(v), color='black', fontweight='bold', fontsize=10)\n",
    "\n",
    "    # Display Table\n",
    "    print(\"\\033[4mTabular View\\033[0m\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    sorted_licensesUsed = sorted(licenses_used.items(), key=lambda kv: kv[1])\n",
    "    print(\"{:<60} {:<40} {:<10}\".format('\\033[1m' + 'License', 'Frequency', 'Percentage' + '\\033[0m'))\n",
    "    totalItems = len(lod_data)\n",
    "    for k, v in sorted_licensesUsed:\n",
    "        print(\"{:<60} {:<40} {:<10}\".format(k, v, str((v * 100.0) / totalItems) + \"%\"))\n",
    "\n",
    "    # Display Plot\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"\\033[4mBar View\\033[0m\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Visualise all data\n",
    "visualiseLicenseData(licensesUsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Visualise Summerised Data\n",
    "licenseLabels = dict({})\n",
    "\n",
    "licenseLabels['https://creativecommons.org/licenses/by/3.0/'] = \"CC-BY-3.0\"\n",
    "licenseLabels['http://reference.data.gov.uk/id/open-government-licence'] = \"OGL-UK\"\n",
    "licenseLabels['http://www.opendefinition.org/licenses/odc-by'] = \"ODC-BY\"\n",
    "licenseLabels['http://www.opendefinition.org/licenses/odc-pddl'] = \"ODC-PDDL\"\n",
    "licenseLabels['http://www.opendefinition.org/licenses/odc-odbl'] = \"ODC-ODBL\"\n",
    "licenseLabels['http://creativecommons.org/licenses/by-nc/2.0/'] = \"CC-BY-NC-2.0\"\n",
    "licenseLabels['http://www.opendefinition.org/licenses/cc-zero'] = \"CC0\"\n",
    "licenseLabels['http://www.opendefinition.org/licenses/cc-by-sa'] = \"CC-BY-SA\"\n",
    "licenseLabels['http://www.opendefinition.org/licenses/cc-by'] = \"CC-BY\"\n",
    "\n",
    "summLicensesUsed = dict({})\n",
    "summLicensesUsed['Other'] = 0\n",
    "for k, v in licensesUsed.items():\n",
    "    if (v < 10):\n",
    "        summLicensesUsed['Other'] = summLicensesUsed['Other'] + v\n",
    "    else:\n",
    "        if k in licenseLabels:\n",
    "            summLicensesUsed[licenseLabels[k]] = v\n",
    "\n",
    "visualiseLicenseData(summLicensesUsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# In the next experiment, we use a regular expression to identify the dataset which potentially have a license assigned\n",
    "# to its description\n",
    "\n",
    "\n",
    "def __tryDecoding(text):\n",
    "    try:\n",
    "        text = str(text, 'utf-8')\n",
    "        return text\n",
    "    except TypeError:\n",
    "        return text\n",
    "\n",
    "\n",
    "def __licenseStringExtractor(text):\n",
    "    potentialText = __tryDecoding(text)\n",
    "\n",
    "    if (potentialText):\n",
    "        str_list = potentialText.splitlines()\n",
    "        str_list = filter(None, str_list)\n",
    "        new_desc = ' '.join([__tryDecoding(x) for x in str_list])\n",
    "\n",
    "        p = re.compile(r'.*(licensed?|copyrighte?d?).*(under|grante?d?|rights?).*', re.IGNORECASE | re.MULTILINE)\n",
    "\n",
    "        m = p.match(new_desc)\n",
    "\n",
    "        return not (m == None)\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "potentialLicence = []\n",
    "for key in lod_data:\n",
    "    if (\"description\" in lod_data[key]):\n",
    "        text = lod_data[key][\"description\"]['en']\n",
    "        if (__licenseStringExtractor(text)):\n",
    "            potentialLicence.append(str(key))\n",
    "\n",
    "print(potentialLicence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (CS715)",
   "language": "python",
   "name": "pycharm-c62c65f4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}